import numpy as np
import matplotlib.image as image
from numpy import linalg as LA
imgsCollection =[]
imgVectorCollection = []
imgVectorTransposeCollection =[]
imgMatrixCorrelationCollection =[]
from PIL import Image
from google.colab import drive
drive.mount('/content/drive')
imgPath = '/content/drive/My Drive/Colab Notebooks/clockwork-angels.jpg'
def checkForDuplicates(rowColumnCollection,row,col):
    duplicateFound=False
    if len(rowColumnCollection)!=0:
        for items in rowColumnCollection:
            trow=items[0]
            tcol=items[1]
            if(trow==row and tcol==col):
                duplicateFound=True
                break
    return duplicateFound

def LoadRandomImg(countOfImage,rowDimension,colDimension):
    img = np.float64(image.imread(imgPath))
    sum = np.zeros((rowDimension * rowDimension, rowDimension * rowDimension))
    rowsStart = np.random.choice(1712 - rowDimension, countOfImage, replace=False)
    colsStart = np.random.choice(3447 - colDimension, countOfImage, replace=False)
    imageCount = 0
    originalImages = []
    for index in range(len(rowsStart)):
        imageCount=imageCount+1
        tempImage=[]
        for i in range(rowDimension):
            t=[]
            for j in range (colDimension):
                t.append(img[(i+rowsStart[index]),(j+colsStart[index])][0])
            tempImage.append(t)
        originalImages.append(tempImage)
        sum = calculateCorrelationMatrix(tempImage,rowDimension,colDimension,sum)
        imgsCollection.append('drive/My Drive/Colab Notebooks/random_%02d.png' % imageCount)
    return sum,originalImages

def calculateCorrelationMatrix(img, rowMax,colMax,sum):
    dimensionalVector = []
    for i in range(rowMax):
        for j in range(colMax):
            dimensionalVector.append([int(img[i][j])])
    dimensionalVectorTranspose = np.transpose(dimensionalVector)
    tempMatrix = np.matmul(dimensionalVector, dimensionalVectorTranspose)
    sum = np.add(sum, tempMatrix)
    return sum

def sortEigenValuesNVectorsInDesc(eigenValues,eigenVectors):
    ids = eigenValues.argsort()[::-1]
    eigenValues = eigenValues[ids]
    eigenVectors = eigenVectors[:,ids]
    return eigenValues,eigenVectors



def createCompressedImage(eigenValues,eigenVectors):
    maxLength = 64
    numberOfEigenValues = len(eigenValues)
    if maxLength<=numberOfEigenValues:
        counter=maxLength
    else:
        counter = numberOfEigenValues
    vrow,vcol = eigenVectors.shape
    allImages=[]
    vCount=0
    for i in  range(64):
        temp=[]
        if(vCount>counter):
            break;
        vCount=vCount+1
        for j in range(vrow):
            temp.append(eigenVectors[j,i])

        newImage = np.array(temp).reshape(16,16)
        image.imsave('drive/My Drive/Colab Notebooks/imageFormed_%02d.png' %i,newImage,cmap='gray')
        allImages.append(newImage)
    y=0
    result = Image.new("RGB", (256, 256))
    lcounter = 0
    for i in range(64):
        if(i<10):
            path='imageFormed_0'+ str(i)+'.png'
        else:
            path='imageFormed_'+str(i)+'.png'
        img=Image.open(path)
        img.thumbnail((18,18),Image.ANTIALIAS)
        if lcounter==0:
            x=0
        else:
            x = lcounter*18
        lcounter=lcounter+1
        w,h = img.size
        result.paste(img, (x, y, x + w, y + h))
        if lcounter==8:
            y=y+18
            lcounter=0
    result.save("drive/My Drive/Colab Notebooks/ImageOut.jpg")



row = col = 16
correlationMatrix,originalImages = LoadRandomImg(100,row,col)
eigenValues,eigenVectors = LA.eigh(correlationMatrix)
eigenValues,eigenVectors = sortEigenValuesNVectorsInDesc(eigenValues,eigenVectors)

import pylab as pl
import numpy as np
from sklearn.decomposition import MiniBatchDictionaryLearning

def plot_result(values,row,col,title):
    plt.figure(figsize=(10, 10))
    plt.title(title)
    for i, comp in enumerate(values):
        plt.subplot(row, col, i + 1)
        plt.imshow(comp.reshape((16,16)), cmap=plt.cm.gray_r,
                   interpolation='nearest')
        plt.xticks(())
        plt.yticks(())
        
def execute_dictionary_learning_usingSkLearn(images):
    data_original = np.array(images)
    mean = data_original.mean()
    data = data_original.reshape(data_original.shape[0],-1)
    mean = np.mean(data,axis=0)
    data -= mean
    
    dico = MiniBatchDictionaryLearning(n_components=350, alpha=1, n_iter=500,transform_algorithm='omp')
    V = dico.fit(data).components_
    plot_result(V[:350],20,20,"Dictionary learning")
    return V
    
    
V = dictionary = execute_dictionary_learning_usingSkLearn(originalImages)
def recreateImagePatches(vec,X):
    Z = np.matmul(vec,np.transpose(vec))
    Xhat = np.matmul(X,Z)
    return Xhat
d = np.array(originalImages)
f_image = []
for i in range(d.shape[0]):
    f_image.append(np.array(d[i]).reshape((256)))
f_image = np.array(f_image)
dictionary.shape

dl = np.transpose(V)
epsilon = 10**(-7)
lmda = .01
from numpy import linalg as LA


def calculateU(Z):
    U = np.zeros((Z.shape[0],Z.shape[1]))
    for i in range(Z.shape[1]):
        for r in range(len(Z[:,i])):
            if abs(Z[r,i])>epsilon:
                U[r,i]=abs(Z[r,i])
            else:
                U[r,i]=epsilon
    return U



def formatX(X):
    resp = np.zeros((X.shape[0],256))
    
    for i, r in enumerate(X):
        temp = X[i].reshape((256))
        resp[i] = (temp.shape)
    return np.transpose(resp)
        
def calculateE(X,W,Z):
    sum = 0
    for i in range(X.shape[1]):
        temp = (np.matmul(W,Z[:,i])).reshape((256,1))
        norm = LA.norm(X[:,i]-temp)**2 
        balanceterm = lmda*LA.norm(Z[:,i],1)
        sum += norm + balanceterm 
    return sum  

def calculateZ(U,W,X):
    Z = np.zeros((U.shape[0],X.shape[1]))
    for i in range(X.shape[1]):
        temp = np.diag(U[:,i])
        interim = LA.inv(np.matmul(np.transpose(W),W) + lmda*temp)
        Z[:,i] = np.matmul(interim, np.matmul(np.transpose(W),X[:,i]))
    return Z

W = dl
X =formatX(np.array(originalImages))
Z = np.random.rand(350,X.shape[1])
U = calculateU(Z)
lastE = calculateE(X,W,Z)
print(lastE)
count=0
absc = 0
y = []

while(count<1000 and absc<20):
    Z = calculateZ(U,W,X)
    currentE = calculateE(X,W,Z)
    if(lastE>currentE):
        y.append(abs(lastE-currentE))
    if(len(y)>0 and y[-1]<2):
        break
    if(lastE>currentE):
        count+=1
        
    lastE=currentE
    U = calculateU(Z)
    absc+=1
print(y[-1])

f_image = np.array(f_image)
vec =np.transpose(eigenVectors[:255])
pca_recreate = recreateImagePatches(vec,f_image)
dl_vec = np.transpose(V)
dl_recreate = recreateImagePatches(dl_vec,f_image)
error_PCA = LA.norm(f_image-pca_recreate)
error_DL = LA.norm(f_image-dl_recreate)
diff_ = LA.norm(pca_recreate-dl_recreate)
print(diff_)
print(error_PCA)
print(error_DL)
print(error_Z)

#!pip install -q spams
import numpy as np
import spams

def _objective(X,D,param,imgname = None):
    
    lparam = _extract_lasso_param(param)
    alpha = spams.lasso(X,D = D,**lparam)
    return alpha
    
def _extract_lasso_param(f_param):
    lst = [ 'L','lambda1','lambda2','mode','pos','ols','numThreads','length_path','verbose','cholesky']
    l_param = {'return_reg_path' : False}
    for x in lst:
        if x in f_param:
            l_param[x] = f_param[x]
    return l_param
param = { 'K' : 350, 
          'lambda1' : 0.15, 'numThreads' : 4,
          'iter' : 500}  
alpha = _objective(np.transpose(f_image),np.transpose(dictionary),param,'dict')

dl = dictionary
epsilon = 10**(-7)
lmda = .01
from numpy import linalg as LA


def calculateU(Z):
    U = np.zeros((Z.shape[0],Z.shape[1]))
    for i in range(Z.shape[1]):
        for r in range(len(Z[:,i])):
            if abs(Z[r,i])>epsilon:
                U[r,i]=abs(Z[r,i])
            else:
                U[r,i]=epsilon
    return U

def formatX(X):
    resp = np.zeros((X.shape[0],256))
    
    for i, r in enumerate(X):
        temp = X[i].reshape((256))
        resp[i] = (temp.shape)
    return np.transpose(resp)
        
def calculateE(X,W,Z):
    sum = 0
    for i in range(X.shape[1]):
        temp = (np.matmul(W,Z[:,i])).reshape((256,1))
        norm = LA.norm(X[:,i]-temp)**2 
        balanceterm = lmda*LA.norm(Z[:,i],1)
        sum += norm + balanceterm 
    return sum  

def calculateZ(U,W,X):
    Z = np.zeros((U.shape[0],X.shape[1]))
    for i in range(X.shape[1]):
        temp =.5* np.diag(U[:,i])
        interim = LA.inv(np.matmul(np.transpose(W),W) + lmda*temp)
        Z[:,i] = np.matmul(interim, np.matmul(np.transpose(W),X[:,i]))
    return Z

W = np.transpose(dl)
X =np.transpose(f_image)
Z = np.random.rand(350,X.shape[1])
print(Z.shape)
U = calculateU(Z)
lastE = calculateE(X,W,Z)
print(lastE)
count=0
absc = 0
y = []
change = []
while(absc<50):
    Z = calculateZ(U,W,X)
    currentE = calculateE(X,W,Z)
    y.append(currentE)
    change.append(abs(lastE-currentE))
    if(len(y)>1 and abs(y[-1]-y[-2])<2):
        break        
    lastE=currentE
    U = calculateU(Z)
    absc+=1
print(y[-1])
LA.norm(alpha-Z)
